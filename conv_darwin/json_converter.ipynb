{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка файла json с сегментацией загрязнений/утрат\n",
    "\n",
    "with open('dirt_output.json', 'r') as f:\n",
    "# with open('lacunae_output.json', 'r') as f:\n",
    "  data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# распаковка необходимой информацию из json файла - изображения и аннотации к ним\n",
    "images = data['images']\n",
    "annotations = data['annotations']\n",
    "categories = {c['id']: c['name'] for c in data['categories']} #соотносим id категории (класса) с именем категории (класса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'license': 0, 'file_name': 'ad000122.png', 'coco_url': 'n/a', 'height': 599, 'width': 710, 'date_captured': '', 'flickr_url': 'n/a', 'darwin_url': 'https://darwin.v7labs.com/api/v2/teams/rsl/uploads/c3ba22ab-75c4-4cff-a2f5-342f8d263d68', 'darwin_workview_url': 'https://darwin.v7labs.com/workview?dataset=653839&item=0189212b-7763-d0aa-0f50-a3de1113c249', 'id': 2877091105, 'tag_ids': []}\n"
     ]
    }
   ],
   "source": [
    "print(images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2556944822: 'dirt'}\n"
     ]
    }
   ],
   "source": [
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414.0 x\n",
      "229.0 y\n",
      "417.0 x\n",
      "230.0 y\n",
      "418.0 x\n",
      "230.0 y\n",
      "419.0 x\n",
      "232.0 y\n"
     ]
    }
   ],
   "source": [
    "#тестовая проверка правильности отображения координат\n",
    "test_list = [414.0, 229.0, 417.0, 230.0, 418.0, 230.0, 419.0, 232.0]\n",
    "for i in test_list:\n",
    "    if isinstance(i, str or dict):\n",
    "        continue\n",
    "    elif not test_list.index(i) %2:\n",
    "        print(str(i) + ' x')\n",
    "    else: \n",
    "        print(str(i) + ' y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция добавления информации в файл\n",
    "def write_to_file(file, str):\n",
    "    with open(file, 'a', encoding = 'utf-8') as f:\n",
    "        f.write(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка значений внутри файла JSON и запись в файл строк с некорректными данными\n",
    "#---- MAIN -----\n",
    "\n",
    "for image in images: #для каждой записи в данных изображения\n",
    "    segment_boxes = [] #пустой список для конвертированных данных\n",
    "    file_name = image[\"file_name\"].replace('.png', '') #данные имени файла без расширения\n",
    "    for annotation in annotations: #для каждой записи в данных сегментации\n",
    "        if annotation['image_id'] == image['id']: #если id изображения соответствует id аннотации\n",
    "            #print(annotation[\"segmentation\"])\n",
    "            #print(image[\"height\"])\n",
    "            #print(image[\"width\"])\n",
    "            bbox = annotation[\"bbox\"] #создаем переменную, содержащую данные рамки bbox - координаты x y w h\n",
    "            # нормализация координат\n",
    "            x, y, w, h = bbox\n",
    "            file_name = 'file_name  ' + str(image[\"file_name\"])\n",
    "            id_annot = 'id annotation  ' + str(annotation['image_id'])\n",
    "            id_img = 'id image  ' + str(image['id'])\n",
    "            img_w = 'img_width(x) ' + str(image['width'])\n",
    "            img_h = 'img_height(y) ' + str(image['height'])\n",
    "            x = x / image['width']\n",
    "            y = y / image['height']\n",
    "            w = w / image['width']\n",
    "            h = h / image['height']\n",
    "            k_x = 1/image['width']\n",
    "            k_y = 1/image['height']\n",
    "            # print('k_y'+str(k_y))\n",
    "            for i in annotation[\"segmentation\"]: #для элемента списка сегментов (список в списке)\n",
    "                \n",
    "                if isinstance(i, dict): # исключение, если в записи есть полигон семантического сегмента - маска (словарь с ключом count), а не сущностного \n",
    "                    continue\n",
    "                else:\n",
    "                    # print(i)\n",
    "                    max_coord = 'макc_значения в списке '+ str(max(i)) #выводим максимальное значение координаты\n",
    "                    # for n in i:\n",
    "                    ind_max = 'индекс макс_значения - чет=x, нечет=y ' + str(i.index(max(i))) #выводим индекс максимального значения, где четные значения относятся к x, а нечетные к y\n",
    "                    final_str = f'{file_name}\\n{id_annot}\\n{id_img}\\n{img_w}\\n{img_h}\\n{max_coord}\\n{ind_max}\\n'\n",
    "                    write_to_file('info.txt', final_str) #запись в файл\n",
    "                    maximum = max(i)\n",
    "                    ind = i.index(max(i))\n",
    "                    if isinstance(i, str or dict): # исключение, если в записи есть полигон семантического сегмента - маска (словарь с ключом count), а не сущностного\n",
    "                        continue\n",
    "                    elif not ind % 2: #если индекс не кратен 2, получаем нормальзованный x (значение от 0 до 1)\n",
    "                        x_norm = maximum / image['width']\n",
    "                        x_norm_k = maximum * k_x\n",
    "                        x_norm_str = 'нормализованный x | коэффициент ' + str(x_norm) + ' '+ str(x_norm_k) #выводим запись нормализованных значений x\n",
    "                        write_to_file('info.txt', f'{x_norm_str}\\n') #запись в файл\n",
    "                        if x_norm_k > 1.0: # если нормализованный x > 1.0, выводим запись об ошибке\n",
    "                            error_x = 'ERROR'\n",
    "                            write_to_file('info.txt', f'{error_x}\\n') #запись в файл\n",
    "                    else:   #если индекс кратен 2\n",
    "                        y_norm = maximum / image['height'] #получаем нормализованный y (значение от 0 до 1)\n",
    "                        y_norm_k = maximum * k_y\n",
    "                        y_norm_str = 'нормализованный y | коэффициент ' + str(y_norm) + ' '+ str(y_norm_k) #выводим нормализованное значение по y\n",
    "                        write_to_file('info.txt', f'{y_norm_str}\\n')\n",
    "                        if y_norm_k > 1.0: # если нормализованный x > 1.0, \n",
    "                            # выводим запись об ошибке\n",
    "                            error_y = 'ERROR'\n",
    "                            write_to_file('info.txt', f'{error_y}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_darwin_to_yolo = 'darwin_to_yolo'\n",
    "# os.mkdir('darwin_to_yolo')\n",
    "# os.mkdir('pylabel_to_yolo')\n",
    "os.getcwd()\n",
    "# os.chdir(r'home_path')\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- MAIN ------\n",
    "# ИСПРАВЛЕНИЕ КООРДИНАТ ФАЙЛА JSON с учетом размера файла изображения \n",
    "# ЗАПИСЬ ФАЙЛОВ С КООРДИНАТАМИ В ФОРМАТЕ INT (В КАЧЕСТВЕ КООРДИНАТ ДЛЯ НОРМАЛИЗАЦИИ И ИСПРАВЛЕНИЯ ИСПОЛЬЗУЮТСЯ ЦЕЛОЧИСЛЕННЫЕ ЗНАЧЕНИЯ)\n",
    "# Более корректный вариант координат\n",
    "\n",
    "for image in images: #для каждой записи в данных изображения\n",
    "    segment_boxes = [] #пустой список для конвертированных данных\n",
    "    file_name = image[\"file_name\"].replace('.png', '') #данные имени файла без расширения\n",
    "    for annotation in annotations: #для каждой записи в аннотациях\n",
    "        if annotation['image_id'] == image['id']: #если id изображения соответствует id аннотации\n",
    "            bbox = annotation[\"bbox\"] #создаем переменную, содержащую данные рамки bbox - координаты x y w h\n",
    "            # нормализация координат\n",
    "            x, y, w, h = bbox\n",
    "            # print('file_name  ' + str(image[\"file_name\"]))\n",
    "            \n",
    "            x = x / float(image['width'])\n",
    "            y = y / float(image['height'])\n",
    "            w = w / float(image['width'])\n",
    "            h = h / float(image['height'])\n",
    "            k_x = 1/float(image['width'])\n",
    "            k_y = 1/float(image['height'])\n",
    "            # print('k_y'+str(k_y))\n",
    "            \n",
    "            for i in annotation[\"segmentation\"]: #для элемента сегмента (список в списке)\n",
    "                if isinstance(i, dict): # исключение, если в записи есть полигон семантического сегмента - маска (словарь с ключом count), а не сущностного \n",
    "                    continue\n",
    "                else:\n",
    "                    # print(i)\n",
    "                    temp_list = []\n",
    "                    # print(\"input_str\" + str(i))\n",
    "                    for ind, meaning in enumerate(i):\n",
    "                        # print(elem[1])\n",
    "                        if isinstance(meaning, str or dict): # исключение, если в записи есть полигон семантического сегмента - маска (словарь с ключом count), а не сущностного \n",
    "                            continue\n",
    "                        elif not ind % 2 and meaning > float(image[\"width\"]):\n",
    "                            meaning = float(image[\"width\"]) - 1\n",
    "                            # print(str(meaning) + \"oops_x\")\n",
    "                            temp_list.append(int(meaning))\n",
    "                        elif ind % 2 and meaning > float(image[\"height\"]):\n",
    "                            meaning = float(image[\"height\"]) - 1\n",
    "                            # print(str(meaning) + \"oops_y\")\n",
    "                            temp_list.append(int(meaning))\n",
    "                        else:\n",
    "                            temp_list.append(int(meaning))\n",
    "                    # print(temp_list)\n",
    "                    \n",
    "                    # нормализация скорректированных координат из temp_list\n",
    "                    norm_list = []\n",
    "                    for ind, a in enumerate(temp_list):\n",
    "                        if not ind % 2:\n",
    "                            x_norm = a*k_x\n",
    "                            norm_list.append(f\"{x_norm:.3}\")\n",
    "                        else:\n",
    "                            y_norm = a*k_y\n",
    "                            norm_list.append(f\"{y_norm:.3}\")\n",
    "                    \n",
    "                    category_id = 0 #dirt\n",
    "                    # category_id = 1 #lacunae\n",
    "                    \n",
    "                    # segment_box_str = f\"{category_id} {(x + w/2):.4} {(y + h/2):.4} {w:.4} {h:.4} {norm_list}\" #вместе с bbox\n",
    "                    segment_box_str = f\"{category_id} {norm_list}\" #только id категории и координаты сегментации без bbox\n",
    "                    # print(segment_box_str)\n",
    "                    segment_boxes.append(segment_box_str)\n",
    "                    # print(segment_boxes)\n",
    "                    \n",
    "                    # запись в файл результатов преобразования\n",
    "                    with open(os.path.join(f\"{path_darwin_to_yolo}\", f\"{file_name}.txt\"), 'w') as f:\n",
    "                    # with open(os.path.join(f\"{path_pylabel_to_yolo}\", f\"{file_name}.txt\"), 'w') as f:\n",
    "                        for text in segment_boxes:\n",
    "                            clear_str = text.replace(\"[\", \"\").replace(\",\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n",
    "                    #         print(clear_str)\n",
    "                            f.write(f\"{clear_str}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting annotations...\n"
     ]
    },
    {
     "ename": "UnrecognizableFileEncoding",
     "evalue": "Unable to load file \\$Recycle.Bin\\S-1-5-21-3374549764-2208607457-1609041802-1001\\$I0JMZ5J.json with any encodings: ['utf-8', 'utf-16', 'utf-32', 'ascii']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnrecognizableFileEncoding\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ksuloko\\Desktop\\RGB\\FindDamage\\img_for_razmetka\\testing\\json_converter.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ksuloko/Desktop/RGB/FindDamage/img_for_razmetka/testing/json_converter.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m files \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mgetcwd()\u001b[39m}\u001b[39;00m\u001b[39m/lacunae_output.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ksuloko/Desktop/RGB/FindDamage/img_for_razmetka/testing/json_converter.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m output_dir \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mgetcwd()\u001b[39m}\u001b[39;00m\u001b[39m/to_yolo\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ksuloko/Desktop/RGB/FindDamage/img_for_razmetka/testing/json_converter.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m convert(annotation_format, files, output_dir)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\darwin\\cli_functions.py:1130\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(format, files, output_dir)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m   1128\u001b[0m     _error(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported export format, currently supported: \u001b[39m\u001b[39m{\u001b[39;00mexport_formats\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1130\u001b[0m export_annotations(parser, files, output_dir, split_sequences\u001b[39m=\u001b[39;49m(\u001b[39mformat\u001b[39;49m \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mdarwin_1.0\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mnifti\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\darwin\\exporter\\exporter.py:62\u001b[0m, in \u001b[0;36mexport_annotations\u001b[1;34m(exporter, file_paths, output_directory, split_sequences)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39mConverts a set of files to a different annotation format.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m    Where the parsed files will be placed after the operation is complete.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConverting annotations...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m exporter(\n\u001b[0;32m     63\u001b[0m     darwin_to_dt_gen(file_paths, split_sequences\u001b[39m=\u001b[39;49msplit_sequences),\n\u001b[0;32m     64\u001b[0m     Path(output_directory),\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConverted annotations saved at \u001b[39m\u001b[39m{\u001b[39;00moutput_directory\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\darwin\\exporter\\formats\\yolo.py:26\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(annotation_files, output_dir)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(annotation_files: Iterable[dt\u001b[39m.\u001b[39mAnnotationFile], output_dir: Path) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m    Exports the given ``AnnotationFile``\\\\s into the YOLO format inside of the given\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m    ``output_dir``.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m        The folder where the new pascalvoc files will be.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     annotation_files \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(annotation_files)\n\u001b[0;32m     28\u001b[0m     class_index \u001b[39m=\u001b[39m build_class_index(annotation_files)\n\u001b[0;32m     30\u001b[0m     \u001b[39mfor\u001b[39;00m annotation_file \u001b[39min\u001b[39;00m annotation_files:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\darwin\\exporter\\exporter.py:31\u001b[0m, in \u001b[0;36mdarwin_to_dt_gen\u001b[1;34m(file_paths, split_sequences)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39msuffix \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m data \u001b[39m=\u001b[39m parse_darwin_json(f, count)\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m data:\n\u001b[0;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mis_video \u001b[39mand\u001b[39;00m split_sequences:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\darwin\\utils\\utils.py:445\u001b[0m, in \u001b[0;36mparse_darwin_json\u001b[1;34m(path, count)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[39mParses the given JSON file in v7's darwin proprietary format. Works for images, split frame\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[39mvideos (treated as images) and playback videos.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m    dictionary.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    443\u001b[0m path \u001b[39m=\u001b[39m Path(path)\n\u001b[1;32m--> 445\u001b[0m data, version \u001b[39m=\u001b[39m load_data_from_file(path)\n\u001b[0;32m    446\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m data:\n\u001b[0;32m    447\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\darwin\\utils\\utils.py:413\u001b[0m, in \u001b[0;36mload_data_from_file\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data_from_file\u001b[39m(path: Path) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\u001b[39mdict\u001b[39m, dt\u001b[39m.\u001b[39mAnnotationFileVersion]:\n\u001b[1;32m--> 413\u001b[0m     data \u001b[39m=\u001b[39m attempt_decode(path)\n\u001b[0;32m    414\u001b[0m     version \u001b[39m=\u001b[39m _parse_version(data)\n\u001b[0;32m    415\u001b[0m     \u001b[39mreturn\u001b[39;00m data, version\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\darwin\\utils\\utils.py:409\u001b[0m, in \u001b[0;36mattempt_decode\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 409\u001b[0m \u001b[39mraise\u001b[39;00m UnrecognizableFileEncoding(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to load file \u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m with any encodings: \u001b[39m\u001b[39m{\u001b[39;00mencodings\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mUnrecognizableFileEncoding\u001b[0m: Unable to load file \\$Recycle.Bin\\S-1-5-21-3374549764-2208607457-1609041802-1001\\$I0JMZ5J.json with any encodings: ['utf-8', 'utf-16', 'utf-32', 'ascii']"
     ]
    }
   ],
   "source": [
    "#попытка конвертировать darwin с помощью существующего пакета в Python py-darwin \n",
    "# pip install darwin-py\n",
    "\n",
    "# from darwin.cli_functions import convert\n",
    "\n",
    "# annotation_format = \"yolo\"\n",
    "# files = f\"{os.getcwd()}/lacunae_output.json\"\n",
    "# output_dir = f\"{os.getcwd()}/to_yolo\"\n",
    "\n",
    "# convert(annotation_format, files, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
